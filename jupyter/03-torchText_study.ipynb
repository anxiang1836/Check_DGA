{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 输出每个cell的运行时间\n",
    "%load_ext autotime\n",
    "# https://github.com/cpcloud/ipython-autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TorchText学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 1.07 ms\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from torchtext import data\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 构建自定义DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 7.92 ms\n"
     ]
    }
   ],
   "source": [
    "class DGA2019(data.Dataset):\n",
    "    def __init__(self,path,test = True):\n",
    "        \n",
    "        tokenize = lambda x : [c for c in x]\n",
    "        self._text_field = data.Field(sequential=True, \n",
    "                                      tokenize=tokenize,\n",
    "                                      lower=True)\n",
    "\n",
    "        self._label_field = data.Field(sequential=False, use_vocab=False)\n",
    "        self.ds_len = 0\n",
    "        \n",
    "        fields = [(\"url\",self._text_field),\n",
    "                 (\"label\",self._label_field)]\n",
    "        examples = []\n",
    "        \n",
    "        print('read data from:{}'.format(path))\n",
    "        with open(path,\"rb\") as f:\n",
    "            urls_data,label_data = pickle.load(f)\n",
    "        self.ds_len = len(urls_data)\n",
    "        \n",
    "        if test:\n",
    "            for url in urls_data:\n",
    "                examples.append(data.Example.fromlist([url,None],fields))\n",
    "        else:\n",
    "            for url,label in zip(urls_data,label_data):\n",
    "                 examples.append(data.Example.fromlist([url,label],fields))\n",
    "\n",
    "        # 调用super调用父类构造方法，产生标准Dataset\n",
    "        super(DGA2019,self).__init__(examples,fields)\n",
    "    \n",
    "    @staticmethod\n",
    "    def sort_key(ex):\n",
    "        return len(ex.text)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.ds_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 843 µs\n"
     ]
    }
   ],
   "source": [
    "base_root = \"pkl_data/\"\n",
    "train_root = base_root + \"train_data\"\n",
    "val_root = base_root + \"val_data\"\n",
    "test_root = base_root + \"test_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read data from:pkl_data/train_data\n",
      "read data from:pkl_data/val_data\n",
      "read data from:pkl_data/test_data\n",
      "time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "train=DGA2019(train_root,test=False)\n",
    "valid=DGA2019(val_root,test=False)\n",
    "test=DGA2019(test_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 11.9 s\n"
     ]
    }
   ],
   "source": [
    "TEXT = train.fields['url']\n",
    "TEXT.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.98 ms\n"
     ]
    }
   ],
   "source": [
    "len(TEXT.vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 初始化vocab.vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([41, 128])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 64.4 ms\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "matrix = torch.randn(len(TEXT.vocab),128)\n",
    "TEXT.vocab.set_vectors(TEXT.vocab.stoi,matrix,128)\n",
    "TEXT.vocab.vectors.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<bound method Vocab._default_unk_index of <torchtext.vocab.Vocab object at 0x1f1236cc0>>, {'<unk>': 0, '<pad>': 1, 'o': 2, 'e': 3, '.': 4, 'c': 5, 'a': 6, 'm': 7, 'i': 8, 'n': 9, 'r': 10, 't': 11, 's': 12, 'u': 13, 'l': 14, 'd': 15, 'b': 16, 'p': 17, 'g': 18, 'h': 19, 'y': 20, 'k': 21, 'f': 22, 'v': 23, 'w': 24, 'x': 25, 'q': 26, 'j': 27, 'z': 28, '1': 29, '2': 30, '-': 31, '4': 32, '3': 33, '5': 34, '8': 35, '6': 36, '7': 37, '0': 38, '9': 39, '_': 40})\n",
      "time: 2.66 ms\n"
     ]
    }
   ],
   "source": [
    "print(TEXT.vocab.stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.81 ms\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data import Iterator,BucketIterator\n",
    "train_iter = data.BucketIterator(dataset=train, batch_size=128, shuffle=True, \n",
    "                                 sort_within_batch=False, repeat=False)\n",
    "valid_iter = data.BucketIterator(dataset=valid, batch_size=128, shuffle=True, \n",
    "                                 sort_within_batch=False, repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14204"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.37 ms\n"
     ]
    }
   ],
   "source": [
    "len(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 9.98 ms\n"
     ]
    }
   ],
   "source": [
    "# 接下来就是构造一个LSTM模型，然后训练一下\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "weight_matrix=TEXT.vocab.vectors\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM,self).__init__()\n",
    "        self.word_embedding=nn.Embedding(len(TEXT.vocab),128)\n",
    "        # 给Embedding进行初始化\n",
    "        self.word_embedding.weight.data.copy_(weight_matrix)\n",
    "        \n",
    "        self.lstm=nn.LSTM(input_size=128,hidden_size=64,num_layers=1)\n",
    "        self.decoder=nn.Linear(64,2)\n",
    "    \n",
    "    def forward(self, sentence):\n",
    "        embeds=self.word_embedding(sentence)\n",
    "        print(embeds.shape)\n",
    "        lstm_out=self.lstm(embeds)[0]\n",
    "        print(lstm_out.shape)\n",
    "        final=lstm_out[-1]\n",
    "        y=self.decoder(final)\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[torchtext.data.batch.Batch of size 8]\n",
      "\t[.url]:[torch.LongTensor of size 32x8]\n",
      "\t[.label]:[torch.LongTensor of size 8]\n",
      "torch.Size([32, 8]) torch.Size([8])\n",
      "time: 9.32 s\n"
     ]
    }
   ],
   "source": [
    "for idx, batch in enumerate(train_iter):\n",
    "    if idx==0:\n",
    "        print(batch)\n",
    "        text, label = batch.url, batch.label\n",
    "        print(text.shape, label.shape)\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.6059950590133667\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.7442505955696106\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.671790599822998\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.8364723324775696\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.5900936126708984\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.623916745185852\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.658275842666626\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.6357868313789368\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6163193583488464\n",
      "torch.Size([28, 8, 128])\n",
      "torch.Size([28, 8, 64])\n",
      "0.8279600143432617\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6172653436660767\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.7244459390640259\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.622336745262146\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.7078301906585693\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.6196842789649963\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.6477929949760437\n",
      "torch.Size([19, 8, 128])\n",
      "torch.Size([19, 8, 64])\n",
      "0.5440577864646912\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.6001467704772949\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.641167402267456\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.5913931131362915\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.9427652955055237\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.6204595565795898\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.8577497005462646\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6064774990081787\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.6290832161903381\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.5480557680130005\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.6379204392433167\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.6523476839065552\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.6136467456817627\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6373488306999207\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.62663733959198\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.5598792433738708\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.5979447960853577\n",
      "torch.Size([20, 8, 128])\n",
      "torch.Size([20, 8, 64])\n",
      "0.8694744110107422\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.6642412543296814\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.6077542901039124\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6142259836196899\n",
      "torch.Size([33, 8, 128])\n",
      "torch.Size([33, 8, 64])\n",
      "0.8522343635559082\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.9014058709144592\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.7678647041320801\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.7312111258506775\n",
      "torch.Size([29, 8, 128])\n",
      "torch.Size([29, 8, 64])\n",
      "0.6984947919845581\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.6684842109680176\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.6240881681442261\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.6578025817871094\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.5305660963058472\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6872133612632751\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.7875084280967712\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.6591665744781494\n",
      "torch.Size([31, 8, 128])\n",
      "torch.Size([31, 8, 64])\n",
      "0.9051107168197632\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.6552525758743286\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.6508259177207947\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.5819370150566101\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.5450443625450134\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.5893750190734863\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6253922581672668\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.5835542678833008\n",
      "torch.Size([24, 8, 128])\n",
      "torch.Size([24, 8, 64])\n",
      "0.5753591060638428\n",
      "torch.Size([19, 8, 128])\n",
      "torch.Size([19, 8, 64])\n",
      "0.7263684868812561\n",
      "torch.Size([20, 8, 128])\n",
      "torch.Size([20, 8, 64])\n",
      "0.6280451416969299\n",
      "torch.Size([19, 8, 128])\n",
      "torch.Size([19, 8, 64])\n",
      "0.7713663578033447\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.5817522406578064\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.6237655282020569\n",
      "torch.Size([28, 8, 128])\n",
      "torch.Size([28, 8, 64])\n",
      "0.7034342885017395\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.6100083589553833\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.594443678855896\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.7482118010520935\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.4460185170173645\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.5525995492935181\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.5233162045478821\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.41833019256591797\n",
      "torch.Size([32, 8, 128])\n",
      "torch.Size([32, 8, 64])\n",
      "0.6606972813606262\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.5794053673744202\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.37107959389686584\n",
      "torch.Size([28, 8, 128])\n",
      "torch.Size([28, 8, 64])\n",
      "0.6835042834281921\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.66806960105896\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.6880818605422974\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.5778115391731262\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.4146840274333954\n",
      "torch.Size([39, 8, 128])\n",
      "torch.Size([39, 8, 64])\n",
      "0.9012009501457214\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.35845470428466797\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.7784542441368103\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.5635091066360474\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.5784162878990173\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.6161478757858276\n",
      "torch.Size([19, 8, 128])\n",
      "torch.Size([19, 8, 64])\n",
      "0.7303749322891235\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6424580216407776\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.5638812780380249\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.45982909202575684\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.7766281962394714\n",
      "torch.Size([29, 8, 128])\n",
      "torch.Size([29, 8, 64])\n",
      "0.6221686601638794\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.5249846577644348\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.49267926812171936\n",
      "torch.Size([16, 8, 128])\n",
      "torch.Size([16, 8, 64])\n",
      "1.149648666381836\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.4749881625175476\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.533953845500946\n",
      "torch.Size([46, 8, 128])\n",
      "torch.Size([46, 8, 64])\n",
      "0.7339231967926025\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.5365972518920898\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.4508332312107086\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.6672608852386475\n",
      "torch.Size([28, 8, 128])\n",
      "torch.Size([28, 8, 64])\n",
      "0.6064528226852417\n",
      "torch.Size([19, 8, 128])\n",
      "torch.Size([19, 8, 64])\n",
      "0.5108577013015747\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.34100502729415894\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.7598631978034973\n",
      "torch.Size([35, 8, 128])\n",
      "torch.Size([35, 8, 64])\n",
      "0.5512183904647827\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.2819434404373169\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.43963950872421265\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.6578744053840637\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.4566723108291626\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.3231552541255951\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.43555551767349243\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.4409645199775696\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.7226542830467224\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.7446255683898926\n",
      "torch.Size([24, 8, 128])\n",
      "torch.Size([24, 8, 64])\n",
      "0.532050609588623\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.47213563323020935\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.38549867272377014\n",
      "torch.Size([19, 8, 128])\n",
      "torch.Size([19, 8, 64])\n",
      "0.4242478609085083\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.32830697298049927\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.6783764362335205\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.5748700499534607\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.4555525779724121\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.7064395546913147\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.4189210534095764\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.7151191234588623\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.4094547927379608\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.46812334656715393\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.6082905530929565\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.32494276762008667\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.2132834941148758\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.2565320134162903\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.5560979843139648\n",
      "torch.Size([28, 8, 128])\n",
      "torch.Size([28, 8, 64])\n",
      "0.5253201723098755\n",
      "torch.Size([31, 8, 128])\n",
      "torch.Size([31, 8, 64])\n",
      "1.132681965827942\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.27981048822402954\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.5801025032997131\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.4633847177028656\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.7845875024795532\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.7006685733795166\n",
      "torch.Size([30, 8, 128])\n",
      "torch.Size([30, 8, 64])\n",
      "0.6853882074356079\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.5045345425605774\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.33525070548057556\n",
      "torch.Size([34, 8, 128])\n",
      "torch.Size([34, 8, 64])\n",
      "0.6729937791824341\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.365293025970459\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.5419981479644775\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.6189416646957397\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.5197913646697998\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.44483518600463867\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.7528737783432007\n",
      "torch.Size([29, 8, 128])\n",
      "torch.Size([29, 8, 64])\n",
      "0.6032600402832031\n",
      "torch.Size([19, 8, 128])\n",
      "torch.Size([19, 8, 64])\n",
      "0.47523200511932373\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.2904200553894043\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.3667067289352417\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.6244915723800659\n",
      "torch.Size([33, 8, 128])\n",
      "torch.Size([33, 8, 64])\n",
      "1.000460147857666\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.7278763055801392\n",
      "torch.Size([34, 8, 128])\n",
      "torch.Size([34, 8, 64])\n",
      "0.7499865889549255\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.5537324547767639\n",
      "torch.Size([21, 8, 128])\n",
      "torch.Size([21, 8, 64])\n",
      "0.34947100281715393\n",
      "torch.Size([26, 8, 128])\n",
      "torch.Size([26, 8, 64])\n",
      "0.7594975233078003\n",
      "torch.Size([23, 8, 128])\n",
      "torch.Size([23, 8, 64])\n",
      "0.3729597330093384\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.6972227096557617\n",
      "torch.Size([22, 8, 128])\n",
      "torch.Size([22, 8, 64])\n",
      "0.39439988136291504\n",
      "torch.Size([25, 8, 128])\n",
      "torch.Size([25, 8, 64])\n",
      "0.3284190595149994\n",
      "torch.Size([27, 8, 128])\n",
      "torch.Size([27, 8, 64])\n",
      "0.3565436005592346\n",
      "torch.Size([21, 8, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-d860dbbb3e99>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpredicted\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcrition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/flyai/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-53-a58c4af37bfe>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0membeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/flyai/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[0;34m(self, string)\u001b[0m\n\u001b[1;32m    400\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    401\u001b[0m             \u001b[0;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 402\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    403\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    404\u001b[0m                 \u001b[0;31m# newlines imply flush in subprocesses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/flyai/lib/python3.6/site-packages/ipykernel/iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[0;34m(self, f)\u001b[0m\n\u001b[1;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;31m# wake event thread (message content is ignored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 205\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    206\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/flyai/lib/python3.6/site-packages/zmq/sugar/socket.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[1;32m    398\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[1;32m    399\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 6.69 s\n"
     ]
    }
   ],
   "source": [
    "model=LSTM()\n",
    "model.train()\n",
    "optimizer=optim.Adam(filter(lambda p:p.requires_grad,model.parameters()),lr=0.01)\n",
    "crition=F.cross_entropy\n",
    "\n",
    "for epoch,batch in enumerate(train_iter):\n",
    "    optimizer.zero_grad()\n",
    "    predicted=model(batch.url)\n",
    "    loss=crition(predicted,batch.label)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(loss.item())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "flyai",
   "language": "python",
   "name": "flyai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
